# Copy to `.env` for local development (do not commit your real `.env`).

# --- Auth ---
# For local development, you can leave `VITE_OAUTH_PORTAL_URL` unset to use the built-in Dev Login.
# For production, set `VITE_OAUTH_PORTAL_URL` to your external OAuth portal base URL (e.g. https://auth.example.com/).
VITE_OAUTH_PORTAL_URL=
VITE_APP_ID=local

# Server-side OAuth API base URL (only needed if you're using an external OAuth provider flow).
OAUTH_SERVER_URL=

# Session signing secret (required)
JWT_SECRET=change_me

# --- Database (MySQL) ---
DATABASE_URL=

# --- Optional: LLM / APIs ---
BUILT_IN_FORGE_API_KEY=
BUILT_IN_FORGE_API_URL=https://api.openai.com
BUILT_IN_FORGE_MODEL=gpt-4o-mini
SEMANTIC_SCHOLAR_API_KEY=

# --- Optional: Semantic Scholar rate limiting (server) ---
# Reduce the chance of HTTP 429s by throttling and caching requests.
SEMANTIC_SCHOLAR_MIN_REQUEST_INTERVAL_MS=1100
SEMANTIC_SCHOLAR_CACHE_TTL_MS=600000
SEMANTIC_SCHOLAR_MAX_RETRIES=5

# --- Optional: LLM reliability (server) ---
# Use `LLM_MODE=mock` to run the pipeline without external network calls.
LLM_MODE=
LLM_TIMEOUT_MS=120000
LLM_MAX_RETRIES=4
LLM_MAX_TOKENS=4096

# --- Optional: integration tests ---
# Enable network + real credentials for tests that hit external APIs.
RUN_INTEGRATION_TESTS=

# --- Optional: generation constraints ---
# Attempts a single LLM pass to hit the target word count (Â±10%) for the main body.
ENFORCE_WORD_COUNT=1
